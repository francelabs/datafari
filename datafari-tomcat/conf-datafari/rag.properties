# All parameters are documented in Datafari RagAPI Confluence documentation

##############################################
###        GLOBAL AI/RAG PROPERTIES        ###
##############################################

ai.enable.rag=false
ai.enable.summarization=false


##############################################
###        WEB SERVICES PARAMETERS         ###
##############################################

ai.api.endpoint=
ai.api.token=
ai.llm.service=openai


##############################################
###             LLM PARAMETERS             ###
##############################################

llm.model=
llm.temperature=0
llm.maxTokens=200

##############################################
###                RETRIEVAL               ###
##############################################

retrieval.method=bm25

##############################################
###         BM25 SEARCH PROPERTIES         ###
##############################################

chunking.maxFiles=3
chunking.chunk.size=3000
rag.operator=OR

##############################################
###         BM25 SEARCH PROPERTIES         ###
##############################################

rrf.topK=50
rrf.rank.constant=60

##############################################
###   IN MEMORY VECTOR SEARCH PROPERTIES   ###
###               DEPRECATED !             ###
##############################################

inMemory.enable.vector.search=false
inMemory.topK=10


##############################################
###               PROMPTING                ###
##############################################

# mapreduce or refine
prompt.chunking.strategy=refine
prompt.max.request.size=40000

##############################################
###              CHAT MEMORY               ###
##############################################
chat.query.rewriting.enabled=false
chat.memory.enabled=false
chat.memory.history.size=6

##############################################
###           SOLR VECTOR SEARCH           ###
##############################################

solr.enable.vector.search=false
solr.embeddings.model=default_model
solr.vector.field=
solr.topK=10

